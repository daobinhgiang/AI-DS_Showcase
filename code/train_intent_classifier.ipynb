{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas>=1.3.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from -r ../requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from -r ../requirements.txt (line 2)) (1.23.5)\n",
      "Requirement already satisfied: transformers==4.30.2 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from -r ../requirements.txt (line 3)) (4.30.2)\n",
      "Requirement already satisfied: tensorflow==2.12.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from -r ../requirements.txt (line 4)) (2.12.0)\n",
      "Requirement already satisfied: datasets>=2.12.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from -r ../requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from -r ../requirements.txt (line 6)) (1.6.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from -r ../requirements.txt (line 7)) (4.67.1)\n",
      "Collecting matplotlib>=3.5.0 (from -r ../requirements.txt (line 8))\n",
      "  Downloading matplotlib-3.10.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Collecting seaborn>=0.12.0 (from -r ../requirements.txt (line 9))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from transformers==4.30.2->-r ../requirements.txt (line 3)) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from transformers==4.30.2->-r ../requirements.txt (line 3)) (0.30.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from transformers==4.30.2->-r ../requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from transformers==4.30.2->-r ../requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from transformers==4.30.2->-r ../requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from transformers==4.30.2->-r ../requirements.txt (line 3)) (2.32.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from transformers==4.30.2->-r ../requirements.txt (line 3)) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from transformers==4.30.2->-r ../requirements.txt (line 3)) (0.5.3)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow==2.12.0->-r ../requirements.txt (line 4)) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (2.2.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (25.2.10)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (3.13.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (0.4.30)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (4.25.7)\n",
      "Requirement already satisfied: setuptools in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (4.13.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (1.71.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (0.31.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from pandas>=1.3.0->-r ../requirements.txt (line 1)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from pandas>=1.3.0->-r ../requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from pandas>=1.3.0->-r ../requirements.txt (line 1)) (2025.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from datasets>=2.12.0->-r ../requirements.txt (line 5)) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from datasets>=2.12.0->-r ../requirements.txt (line 5)) (0.3.8)\n",
      "Requirement already satisfied: xxhash in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from datasets>=2.12.0->-r ../requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from datasets>=2.12.0->-r ../requirements.txt (line 5)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets>=2.12.0->-r ../requirements.txt (line 5)) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from datasets>=2.12.0->-r ../requirements.txt (line 5)) (3.11.18)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from scikit-learn>=1.0.0->-r ../requirements.txt (line 6)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from scikit-learn>=1.0.0->-r ../requirements.txt (line 6)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from scikit-learn>=1.0.0->-r ../requirements.txt (line 6)) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tqdm>=4.64.0->-r ../requirements.txt (line 7)) (0.4.6)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.5.0->-r ../requirements.txt (line 8))\n",
      "  Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.5.0->-r ../requirements.txt (line 8))\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.5.0->-r ../requirements.txt (line 8))\n",
      "  Downloading fonttools-4.57.0-cp310-cp310-win_amd64.whl.metadata (104 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.5.0->-r ../requirements.txt (line 8))\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib>=3.5.0->-r ../requirements.txt (line 8))\n",
      "  Downloading pillow-11.2.1-cp310-cp310-win_amd64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.5.0->-r ../requirements.txt (line 8))\n",
      "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from aiohttp->datasets>=2.12.0->-r ../requirements.txt (line 5)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from aiohttp->datasets>=2.12.0->-r ../requirements.txt (line 5)) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from aiohttp->datasets>=2.12.0->-r ../requirements.txt (line 5)) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from aiohttp->datasets>=2.12.0->-r ../requirements.txt (line 5)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from aiohttp->datasets>=2.12.0->-r ../requirements.txt (line 5)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from aiohttp->datasets>=2.12.0->-r ../requirements.txt (line 5)) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from aiohttp->datasets>=2.12.0->-r ../requirements.txt (line 5)) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from aiohttp->datasets>=2.12.0->-r ../requirements.txt (line 5)) (1.20.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from requests->transformers==4.30.2->-r ../requirements.txt (line 3)) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from requests->transformers==4.30.2->-r ../requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from requests->transformers==4.30.2->-r ../requirements.txt (line 3)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from requests->transformers==4.30.2->-r ../requirements.txt (line 3)) (2025.1.31)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (0.45.1)\n",
      "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (0.4.30)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (0.5.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (2.39.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (3.8)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (2.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (3.0.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow==2.12.0->-r ../requirements.txt (line 4)) (3.2.2)\n",
      "Downloading matplotlib-3.10.1-cp310-cp310-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 5.0/8.1 MB 23.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 23.7 MB/s eta 0:00:00\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Downloading contourpy-1.3.2-cp310-cp310-win_amd64.whl (221 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.57.0-cp310-cp310-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 17.8 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp310-cp310-win_amd64.whl (71 kB)\n",
      "Downloading pillow-11.2.1-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.7/2.7 MB 25.7 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
      "Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n",
      "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.2.1 pyparsing-3.2.3 seaborn-0.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, AutoConfig\n",
    "from transformers.models.distilbert import TFDistilBertForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n",
      "Transformers version: 4.30.2\n"
     ]
    }
   ],
   "source": [
    "print(f'TensorFlow version: {tf.__version__}'); print(f'Transformers version: {transformers.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variable to enable progress bar\n",
    "os.environ[\"TQDM_NOTEBOOK\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback with enhanced progress bar\n",
    "class TqdmProgressCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, epochs, metrics=None, overall_bar=True):\n",
    "        super(TqdmProgressCallback, self).__init__()\n",
    "        self.epochs = epochs\n",
    "        self.metrics = metrics or []\n",
    "        self.overall_bar = overall_bar\n",
    "        self.epoch_start_time = None\n",
    "        \n",
    "    def on_train_begin(self, logs=None):\n",
    "        if self.overall_bar:\n",
    "            self.overall_progress = tqdm(total=self.epochs, desc='Training Progress', position=0)\n",
    "        \n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.overall_bar:\n",
    "            self.overall_progress.close()\n",
    "    \n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.epoch_progress = tqdm(\n",
    "            desc=f'Epoch {epoch+1}/{self.epochs}',\n",
    "            position=1,\n",
    "            leave=True\n",
    "        )\n",
    "        self.current_step = 0\n",
    "        self.steps = self.params['steps']\n",
    "        self.epoch_start_time = time.time()\n",
    "        \n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self.current_step += 1\n",
    "        self.epoch_progress.update(1)\n",
    "        self.epoch_progress.total = self.steps\n",
    "        \n",
    "        # Update metrics in description\n",
    "        metrics_str = ' - '.join(f'{m}: {logs.get(m, 0):.4f}' for m in self.metrics if m in logs)\n",
    "        self.epoch_progress.set_description(\n",
    "            f'Epoch {self.epoch + 1}/{self.epochs} - {metrics_str}'\n",
    "        )\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.epoch_progress.close()\n",
    "        \n",
    "        # Collect all available metrics\n",
    "        metrics_str = ' - '.join(f'{k}: {v:.4f}' for k, v in logs.items())\n",
    "        epoch_time = time.time() - self.epoch_start_time\n",
    "        \n",
    "        # Print a summary for the epoch including time taken\n",
    "        print(f\"Epoch {epoch+1}/{self.epochs} completed in {epoch_time:.2f}s - {metrics_str}\")\n",
    "        \n",
    "        if self.overall_bar:\n",
    "            self.overall_progress.update(1)\n",
    "            # Update overall progress bar with key metrics (loss and accuracy)\n",
    "            val_acc = logs.get('val_accuracy', 0)\n",
    "            train_acc = logs.get('accuracy', 0)\n",
    "            self.overall_progress.set_description(\n",
    "                f'Training Progress - Loss: {logs.get(\"loss\", 0):.4f} - Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f}'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Finder class\n",
    "class LRFinder:\n",
    "    def __init__(self, model, min_lr=1e-7, max_lr=1e-2, steps=30):\n",
    "        self.model = model\n",
    "        self.min_lr = min_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.steps = steps\n",
    "        self.history = {\"lr\": [], \"loss\": []}\n",
    "        \n",
    "    def find(self, dataset, batch_size=16, beta=0.98):\n",
    "        print(\"Starting Learning Rate Finder...\")\n",
    "        # Save original weights\n",
    "        original_weights = self.model.get_weights()\n",
    "        \n",
    "        # Calculate step factor\n",
    "        step_factor = (self.max_lr / self.min_lr) ** (1 / self.steps)\n",
    "        lr = self.min_lr\n",
    "        \n",
    "        # Prepare dataset\n",
    "        batched_dataset = dataset.batch(batch_size)\n",
    "        \n",
    "        # Initialize optimizer with minimum learning rate\n",
    "        self.model.optimizer.lr.assign(lr)\n",
    "        \n",
    "        # Training loop with progress bar\n",
    "        avg_loss = 0\n",
    "        progress_bar = tqdm(total=self.steps, desc=f\"Finding optimal learning rate\", position=0)\n",
    "        \n",
    "        for step, (x, y) in enumerate(batched_dataset):\n",
    "            if step >= self.steps:\n",
    "                break\n",
    "                \n",
    "            # Update learning rate for this batch\n",
    "            lr = self.min_lr * (step_factor ** step)\n",
    "            self.model.optimizer.lr.assign(lr)\n",
    "            \n",
    "            # Compute loss\n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = self.model(x, training=True)\n",
    "                loss = self.model.compiled_loss(y, logits)\n",
    "                \n",
    "            # Apply gradients\n",
    "            grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "            self.model.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "            \n",
    "            # Track loss and lr\n",
    "            loss_value = float(loss)\n",
    "            avg_loss = beta * avg_loss + (1 - beta) * loss_value\n",
    "            smoothed_loss = avg_loss / (1 - beta ** (step + 1))\n",
    "            \n",
    "            self.history[\"lr\"].append(lr)\n",
    "            self.history[\"loss\"].append(smoothed_loss)\n",
    "            \n",
    "            # Update progress bar with current learning rate and loss\n",
    "            progress_bar.set_description(\n",
    "                f\"Finding optimal learning rate - LR: {lr:.8f} - Loss: {smoothed_loss:.4f}\"\n",
    "            )\n",
    "            progress_bar.update(1)\n",
    "            \n",
    "            # Stop if loss explodes\n",
    "            if step > 0 and smoothed_loss > 4 * self.history[\"loss\"][0]:\n",
    "                progress_bar.set_description(\n",
    "                    f\"Stopping search - Loss exploded at LR: {lr:.8f}\"\n",
    "                )\n",
    "                break\n",
    "        \n",
    "        progress_bar.close()\n",
    "                \n",
    "        # Restore original weights\n",
    "        self.model.set_weights(original_weights)\n",
    "        \n",
    "    def plot(self, skip_start=10, skip_end=5):\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(self.history[\"lr\"][skip_start:-skip_end], \n",
    "                 self.history[\"loss\"][skip_start:-skip_end])\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel('Learning Rate')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Learning Rate Finder')\n",
    "        plt.savefig('lr_finder_plot.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Find the learning rate with the steepest negative gradient\n",
    "        losses = self.history[\"loss\"][skip_start:-skip_end]\n",
    "        lrs = self.history[\"lr\"][skip_start:-skip_end]\n",
    "        min_grad_idx = np.argmin(np.gradient(losses))\n",
    "        suggested_lr = lrs[min_grad_idx]\n",
    "        \n",
    "        # Find the point with minimum loss\n",
    "        min_loss_idx = np.argmin(losses)\n",
    "        min_loss_lr = lrs[min_loss_idx]\n",
    "        \n",
    "        print(f\"Suggested learning rate (steepest slope): {suggested_lr:.6f}\")\n",
    "        print(f\"Learning rate with minimum loss: {min_loss_lr:.6f}\")\n",
    "        return suggested_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.128305161640991e-07\n"
     ]
    }
   ],
   "source": [
    "print (suggested_lr)\n",
    "# print (2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed data\n",
    "input_ids = np.load('input_ids.npy')\n",
    "attention_mask = np.load('attention_mask.npy')\n",
    "labels = np.load('labels.npy')\n",
    "label_classes = np.load('intent_encoder.npy', allow_pickle=True)\n",
    "\n",
    "# Create mappings\n",
    "id2label = {idx: label for idx, label in enumerate(label_classes)}\n",
    "label2id = {label: idx for idx, label in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and validation sets\n",
    "indices = np.arange(len(labels))\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx = indices[:int(0.8 * len(indices))]\n",
    "val_idx = indices[int(0.8 * len(indices)):]\n",
    "\n",
    "train_input_ids = input_ids[train_idx]\n",
    "train_attention_mask = attention_mask[train_idx]\n",
    "train_labels = labels[train_idx]\n",
    "\n",
    "val_input_ids = input_ids[val_idx]\n",
    "val_attention_mask = attention_mask[val_idx]\n",
    "val_labels = labels[val_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Create TensorFlow datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "        \"input_ids\": train_input_ids,\n",
    "        \"attention_mask\": train_attention_mask\n",
    "    }, train_labels)).shuffle(1000).batch(16)\n",
    "    \n",
    "val_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "        \"input_ids\": val_input_ids,\n",
    "        \"attention_mask\": val_attention_mask\n",
    "    }, val_labels)).batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create the tokenizer first\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize config and model\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=len(label_classes),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = TFDistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Keras native training instead of TFTrainer (which is deprecated)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metrics = [\n",
    "    tf.keras.metrics.SparseCategoricalAccuracy('accuracy'),\n",
    "    tf.keras.metrics.SparseCategoricalCrossentropy(name='cross_entropy', from_logits=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Learning Rate Finder...\n",
      "Starting Learning Rate Finder...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding optimal learning rate - LR: 0.00000479 - Loss: 1.6103:  25%|██▌       | 25/100 [02:30<07:30,  6.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested learning rate (steepest slope): 0.000001\n",
      "Learning rate with minimum loss: 0.000002\n",
      "Using learning rate: 8.128305161640991e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=float32, numpy=8.1283054e-07>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unbatched_train_dataset = tf.data.Dataset.from_tensor_slices(({\n",
    "        \"input_ids\": train_input_ids,\n",
    "        \"attention_mask\": train_attention_mask\n",
    "    }, train_labels)).shuffle(1000)\n",
    "    \n",
    "    # Run learning rate finder\n",
    "print(\"Running Learning Rate Finder...\")\n",
    "lr_finder = LRFinder(model, min_lr=1e-7, max_lr=1, steps=100)\n",
    "lr_finder.find(unbatched_train_dataset)\n",
    "suggested_lr = lr_finder.plot()\n",
    "    \n",
    "    # You can use the suggested learning rate or keep the default\n",
    "print(f\"Using learning rate: {suggested_lr}\")\n",
    "model.optimizer.lr.assign(suggested_lr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1/5\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.6115 - accuracy: 0.1675 - cross_entropy: 1.6115WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227ED4B4310>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227ED4B4310>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E9D67040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E9D67040>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D6129690>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D6129690>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0EDB670>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0EDB670>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E943F9A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E943F9A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0DD0A90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0DD0A90>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\model_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\model_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 106s 4s/step - loss: 1.6115 - accuracy: 0.1675 - cross_entropy: 1.6115 - val_loss: 1.6071 - val_accuracy: 0.1800 - val_cross_entropy: 1.6071\n",
      "Epoch 2/5\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.6052 - accuracy: 0.2150 - cross_entropy: 1.6052WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227ED4B4310>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227ED4B4310>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E9D67040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E9D67040>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D6129690>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D6129690>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0EDB670>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0EDB670>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E943F9A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E943F9A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0DD0A90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0DD0A90>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\model_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\model_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 138s 6s/step - loss: 1.6052 - accuracy: 0.2150 - cross_entropy: 1.6052 - val_loss: 1.6020 - val_accuracy: 0.1900 - val_cross_entropy: 1.6020\n",
      "Epoch 3/5\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.6018 - accuracy: 0.1900 - cross_entropy: 1.6018WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227ED4B4310>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227ED4B4310>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E9D67040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E9D67040>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D6129690>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D6129690>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0EDB670>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0EDB670>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E943F9A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E943F9A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0DD0A90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0DD0A90>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\model_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\model_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 174s 7s/step - loss: 1.6018 - accuracy: 0.1900 - cross_entropy: 1.6018 - val_loss: 1.5963 - val_accuracy: 0.2600 - val_cross_entropy: 1.5963\n",
      "Epoch 4/5\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.5950 - accuracy: 0.2625 - cross_entropy: 1.5950WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227ED4B4310>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227ED4B4310>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E9D67040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E9D67040>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D6129690>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D6129690>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0EDB670>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0EDB670>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E943F9A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E943F9A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0DD0A90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0DD0A90>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\model_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\model_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 229s 9s/step - loss: 1.5950 - accuracy: 0.2625 - cross_entropy: 1.5950 - val_loss: 1.5899 - val_accuracy: 0.2800 - val_cross_entropy: 1.5899\n",
      "Epoch 5/5\n",
      "25/25 [==============================] - ETA: 0s - loss: 1.5896 - accuracy: 0.2800 - cross_entropy: 1.5896WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227ED4B4310>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227ED4B4310>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E9D67040>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E9D67040>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D6129690>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D6129690>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0EDB670>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0EDB670>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E943F9A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227E943F9A0>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0DD0A90>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x00000227D0DD0A90>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla, embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses while saving (showing 5 of 165). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./checkpoints\\model_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 240s 10s/step - loss: 1.5896 - accuracy: 0.2800 - cross_entropy: 1.5896 - val_loss: 1.5822 - val_accuracy: 0.3500 - val_cross_entropy: 1.5822\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath='./checkpoints/model_{epoch}',\n",
    "            save_best_only=True,\n",
    "            monitor='val_loss'\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./intent_classifier\\\\tokenizer_config.json',\n",
       " './intent_classifier\\\\special_tokens_map.json',\n",
       " './intent_classifier\\\\vocab.txt',\n",
       " './intent_classifier\\\\added_tokens.json',\n",
       " './intent_classifier\\\\tokenizer.json')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./intent_classifier\")\n",
    "tokenizer.save_pretrained(\"./intent_classifier\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating final model...\n",
      "7/7 [==============================] - 11s 2s/step - loss: 0.3880 - accuracy: 0.8100\n",
      "Validation loss: 0.38803669810295105\n",
      "Validation accuracy: 0.8100000023841858\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"Evaluating final model...\")\n",
    "results = model.evaluate(val_dataset)\n",
    "print(f\"Validation loss: {results[0]}\")\n",
    "print(f\"Validation accuracy: {results[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Save the label mappings\n",
    "np.save('./intent_classifier/label_classes.npy', label_classes)\n",
    "with open('./intent_classifier/label_mapping.txt', 'w') as f:\n",
    "    for label, idx in label2id.items():\n",
    "        f.write(f\"{label}: {idx}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define compute metrics function\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    report = classification_report(labels, predictions, target_names=list(label2id.keys()), output_dict=True)\n",
    "    \n",
    "    # Extract metrics from the classification report\n",
    "    result = {\n",
    "        \"accuracy\": accuracy,\n",
    "    }\n",
    "    \n",
    "    # Add precision, recall, and f1 for each class\n",
    "    for label, idx in label2id.items():\n",
    "        if label in report:\n",
    "            result[f\"{label}_precision\"] = report[label][\"precision\"]\n",
    "            result[f\"{label}_recall\"] = report[label][\"recall\"]\n",
    "            result[f\"{label}_f1\"] = report[label][\"f1-score\"]\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TFTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    disable_tqdm=False,  # Enable progress bar\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "trainer = TFTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\trainer_tf.py\", line 710, in distributed_training_steps  *\n        self.args.strategy.run(self.apply_gradients, inputs)\n    File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\trainer_tf.py\", line 653, in apply_gradients  *\n        gradients = self.training_step(features, labels, nb_instances_in_global_batch)\n    File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\trainer_tf.py\", line 636, in training_step  *\n        per_example_loss, _ = self.run_model(features, labels, True)\n    File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\trainer_tf.py\", line 755, in run_model  *\n        outputs = self.model(features, labels=labels, training=training)[:2]\n    File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_filevrq1svx0.py\", line 37, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_filezmtbaml_.py\", line 17, in tf__call\n        distilbert_output = ag__.converted_call(ag__.ld(self).distilbert, (), dict(input_ids=ag__.ld(input_ids), attention_mask=ag__.ld(attention_mask), head_mask=ag__.ld(head_mask), inputs_embeds=ag__.ld(inputs_embeds), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_filevrq1svx0.py\", line 37, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_fileq1kb6s64.py\", line 93, in tf__call\n        embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (ag__.ld(input_ids),), dict(inputs_embeds=ag__.ld(inputs_embeds)), fscope)\n    File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_fileepzlanco.py\", line 54, in tf__call\n        final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n\n    ValueError: Exception encountered when calling layer 'tf_distil_bert_for_sequence_classification' (type TFDistilBertForSequenceClassification).\n    \n    in user code:\n    \n        File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 712, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 720, in call  *\n            distilbert_output = self.distilbert(\n        File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_filevrq1svx0.py\", line 37, in tf__run_call_with_unpacked_inputs\n            retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n        File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_fileq1kb6s64.py\", line 93, in tf__call\n            embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (ag__.ld(input_ids),), dict(inputs_embeds=ag__.ld(inputs_embeds)), fscope)\n        File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_fileepzlanco.py\", line 54, in tf__call\n            final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n    \n        ValueError: Exception encountered when calling layer 'distilbert' (type TFDistilBertMainLayer).\n        \n        in user code:\n        \n            File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 712, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 402, in call  *\n                embedding_output = self.embeddings(input_ids, inputs_embeds=inputs_embeds)  # (bs, seq_length, dim)\n            File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_fileepzlanco.py\", line 54, in tf__call\n                final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n        \n            ValueError: Exception encountered when calling layer 'embeddings' (type TFEmbeddings).\n            \n            in user code:\n            \n                File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 124, in call  *\n                    final_embeddings = self.LayerNorm(inputs=final_embeddings)\n                File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n            \n                ValueError: Exception encountered when calling layer 'LayerNorm' (type LayerNormalization).\n                \n                Cannot reshape a tensor with 768 elements to shape [1,1,128,1] (128 elements) for '{{node tf_distil_bert_for_sequence_classification/distilbert/embeddings/LayerNorm/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](tf_distil_bert_for_sequence_classification/distilbert/embeddings/LayerNorm/Reshape/ReadVariableOp, tf_distil_bert_for_sequence_classification/distilbert/embeddings/LayerNorm/Reshape/shape)' with input shapes: [768], [4] and with input tensors computed as partial shapes: input[1] = [1,1,128,1].\n                \n                Call arguments received by layer 'LayerNorm' (type LayerNormalization):\n                  • inputs=tf.Tensor(shape=(16, 16, 128, 768), dtype=float32)\n            \n            \n            Call arguments received by layer 'embeddings' (type TFEmbeddings):\n              • input_ids=tf.Tensor(shape=(16, 16, 128), dtype=int32)\n              • position_ids=None\n              • inputs_embeds=None\n              • training=True\n        \n        \n        Call arguments received by layer 'distilbert' (type TFDistilBertMainLayer):\n          • input_ids=tf.Tensor(shape=(16, 16, 128), dtype=int32)\n          • attention_mask=tf.Tensor(shape=(16, 16, 128), dtype=int32)\n          • head_mask=None\n          • inputs_embeds=None\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=True\n    \n    \n    Call arguments received by layer 'tf_distil_bert_for_sequence_classification' (type TFDistilBertForSequenceClassification):\n      • input_ids={'input_ids': 'tf.Tensor(shape=(16, 16, 128), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(16, 16, 128), dtype=int32)'}\n      • attention_mask=None\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • labels=tf.Tensor(shape=(16, 16), dtype=int32)\n      • training=True\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting training...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\trainer_tf.py:569\u001b[0m, in \u001b[0;36mTFTrainer.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    566\u001b[0m     steps_trained_in_current_epoch \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m--> 569\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistributed_training_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m=\u001b[39m iterations\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_logging \u001b[38;5;241m=\u001b[39m epoch_iter \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps_per_epoch\n",
      "File \u001b[1;32mc:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file5xihnqyl.py:11\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__distributed_training_steps\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m      9\u001b[0m nb_instances_in_batch \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_compute_nb_instances, (ag__\u001b[38;5;241m.\u001b[39mld(batch),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     10\u001b[0m inputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_get_step_inputs, (ag__\u001b[38;5;241m.\u001b[39mld(batch), ag__\u001b[38;5;241m.\u001b[39mld(nb_instances_in_batch)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m---> 11\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileodojba0b.py:111\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__apply_gradients\u001b[1;34m(self, features, labels, nb_instances_in_global_batch)\u001b[0m\n\u001b[0;32m    109\u001b[0m reduced_features \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreduced_features\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    110\u001b[0m _ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 111\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileodojba0b.py:18\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__apply_gradients.<locals>.if_body_4\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mif_body_4\u001b[39m():\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m labels, features\n\u001b[1;32m---> 18\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb_instances_in_global_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mapply_gradients, (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mlist\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mzip\u001b[39m), (ag__\u001b[38;5;241m.\u001b[39mld(gradients), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filek06hwj9y.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__training_step\u001b[1;34m(self, features, labels, nb_instances_in_global_batch)\u001b[0m\n\u001b[0;32m     13\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     14\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 15\u001b[0m (per_example_loss, _) \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m scaled_loss \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(per_example_loss) \u001b[38;5;241m/\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mcast, (ag__\u001b[38;5;241m.\u001b[39mld(nb_instances_in_global_batch),), \u001b[38;5;28mdict\u001b[39m(dtype\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(per_example_loss)\u001b[38;5;241m.\u001b[39mdtype), fscope)\n\u001b[0;32m     17\u001b[0m gradients \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mgradients, (ag__\u001b[38;5;241m.\u001b[39mld(scaled_loss), ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileahfeqf6_.py:52\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_model\u001b[1;34m(self, features, labels, training)\u001b[0m\n\u001b[0;32m     50\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mmodel, (ag__\u001b[38;5;241m.\u001b[39mld(features),), \u001b[38;5;28mdict\u001b[39m(labels\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(labels), training\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(training)), fscope)[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     51\u001b[0m outputs \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefined(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 52\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mif_stmt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mif_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melse_body_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_state_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moutputs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m (loss, logits) \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(outputs)[:\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_state_2\u001b[39m():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileahfeqf6_.py:50\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_model.<locals>.else_body_1\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21melse_body_1\u001b[39m():\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mnonlocal\u001b[39;00m outputs\n\u001b[1;32m---> 50\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filevrq1svx0.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(func), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m),), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(unpacked_inputs)), fscope)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filezmtbaml_.py:17\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, labels, training)\u001b[0m\n\u001b[0;32m     15\u001b[0m do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     16\u001b[0m retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mUndefinedReturnValue()\n\u001b[1;32m---> 17\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistilbert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(distilbert_output)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(hidden_state)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filevrq1svx0.py:37\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__run_call_with_unpacked_inputs\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(func), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m),), \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(unpacked_inputs)), fscope)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileq1kb6s64.py:93\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, training)\u001b[0m\n\u001b[0;32m     91\u001b[0m     head_mask \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mnum_hidden_layers\n\u001b[0;32m     92\u001b[0m ag__\u001b[38;5;241m.\u001b[39mif_stmt(ag__\u001b[38;5;241m.\u001b[39mld(head_mask) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, if_body_4, else_body_4, get_state_4, set_state_4, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead_mask\u001b[39m\u001b[38;5;124m'\u001b[39m,), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m tfmr_output \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtransformer, (ag__\u001b[38;5;241m.\u001b[39mld(embedding_output), ag__\u001b[38;5;241m.\u001b[39mld(attention_mask), ag__\u001b[38;5;241m.\u001b[39mld(head_mask), ag__\u001b[38;5;241m.\u001b[39mld(output_attentions), ag__\u001b[38;5;241m.\u001b[39mld(output_hidden_states), ag__\u001b[38;5;241m.\u001b[39mld(return_dict)), \u001b[38;5;28mdict\u001b[39m(training\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(training)), fscope)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileepzlanco.py:54\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[1;34m(self, input_ids, position_ids, inputs_embeds, training)\u001b[0m\n\u001b[0;32m     52\u001b[0m position_embeds \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mgather, (), \u001b[38;5;28mdict\u001b[39m(params\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mposition_embeddings, indices\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(position_ids)), fscope)\n\u001b[0;32m     53\u001b[0m final_embeddings \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(inputs_embeds) \u001b[38;5;241m+\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(position_embeds)\n\u001b[1;32m---> 54\u001b[0m final_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLayerNorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m final_embeddings \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mdropout, (), \u001b[38;5;28mdict\u001b[39m(inputs\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(final_embeddings), training\u001b[38;5;241m=\u001b[39mag__\u001b[38;5;241m.\u001b[39mld(training)), fscope)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\trainer_tf.py\", line 710, in distributed_training_steps  *\n        self.args.strategy.run(self.apply_gradients, inputs)\n    File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\trainer_tf.py\", line 653, in apply_gradients  *\n        gradients = self.training_step(features, labels, nb_instances_in_global_batch)\n    File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\trainer_tf.py\", line 636, in training_step  *\n        per_example_loss, _ = self.run_model(features, labels, True)\n    File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\trainer_tf.py\", line 755, in run_model  *\n        outputs = self.model(features, labels=labels, training=training)[:2]\n    File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_filevrq1svx0.py\", line 37, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_filezmtbaml_.py\", line 17, in tf__call\n        distilbert_output = ag__.converted_call(ag__.ld(self).distilbert, (), dict(input_ids=ag__.ld(input_ids), attention_mask=ag__.ld(attention_mask), head_mask=ag__.ld(head_mask), inputs_embeds=ag__.ld(inputs_embeds), output_attentions=ag__.ld(output_attentions), output_hidden_states=ag__.ld(output_hidden_states), return_dict=ag__.ld(return_dict), training=ag__.ld(training)), fscope)\n    File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_filevrq1svx0.py\", line 37, in tf__run_call_with_unpacked_inputs\n        retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n    File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_fileq1kb6s64.py\", line 93, in tf__call\n        embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (ag__.ld(input_ids),), dict(inputs_embeds=ag__.ld(inputs_embeds)), fscope)\n    File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_fileepzlanco.py\", line 54, in tf__call\n        final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n\n    ValueError: Exception encountered when calling layer 'tf_distil_bert_for_sequence_classification' (type TFDistilBertForSequenceClassification).\n    \n    in user code:\n    \n        File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 712, in run_call_with_unpacked_inputs  *\n            return func(self, **unpacked_inputs)\n        File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 720, in call  *\n            distilbert_output = self.distilbert(\n        File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_filevrq1svx0.py\", line 37, in tf__run_call_with_unpacked_inputs\n            retval_ = ag__.converted_call(ag__.ld(func), (ag__.ld(self),), dict(**ag__.ld(unpacked_inputs)), fscope)\n        File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_fileq1kb6s64.py\", line 93, in tf__call\n            embedding_output = ag__.converted_call(ag__.ld(self).embeddings, (ag__.ld(input_ids),), dict(inputs_embeds=ag__.ld(inputs_embeds)), fscope)\n        File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_fileepzlanco.py\", line 54, in tf__call\n            final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n    \n        ValueError: Exception encountered when calling layer 'distilbert' (type TFDistilBertMainLayer).\n        \n        in user code:\n        \n            File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\modeling_tf_utils.py\", line 712, in run_call_with_unpacked_inputs  *\n                return func(self, **unpacked_inputs)\n            File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 402, in call  *\n                embedding_output = self.embeddings(input_ids, inputs_embeds=inputs_embeds)  # (bs, seq_length, dim)\n            File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                raise e.with_traceback(filtered_tb) from None\n            File \"C:\\Users\\gdaob\\AppData\\Local\\Temp\\__autograph_generated_fileepzlanco.py\", line 54, in tf__call\n                final_embeddings = ag__.converted_call(ag__.ld(self).LayerNorm, (), dict(inputs=ag__.ld(final_embeddings)), fscope)\n        \n            ValueError: Exception encountered when calling layer 'embeddings' (type TFEmbeddings).\n            \n            in user code:\n            \n                File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_tf_distilbert.py\", line 124, in call  *\n                    final_embeddings = self.LayerNorm(inputs=final_embeddings)\n                File \"c:\\Users\\gdaob\\anaconda3\\envs\\intent-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n                    raise e.with_traceback(filtered_tb) from None\n            \n                ValueError: Exception encountered when calling layer 'LayerNorm' (type LayerNormalization).\n                \n                Cannot reshape a tensor with 768 elements to shape [1,1,128,1] (128 elements) for '{{node tf_distil_bert_for_sequence_classification/distilbert/embeddings/LayerNorm/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](tf_distil_bert_for_sequence_classification/distilbert/embeddings/LayerNorm/Reshape/ReadVariableOp, tf_distil_bert_for_sequence_classification/distilbert/embeddings/LayerNorm/Reshape/shape)' with input shapes: [768], [4] and with input tensors computed as partial shapes: input[1] = [1,1,128,1].\n                \n                Call arguments received by layer 'LayerNorm' (type LayerNormalization):\n                  • inputs=tf.Tensor(shape=(16, 16, 128, 768), dtype=float32)\n            \n            \n            Call arguments received by layer 'embeddings' (type TFEmbeddings):\n              • input_ids=tf.Tensor(shape=(16, 16, 128), dtype=int32)\n              • position_ids=None\n              • inputs_embeds=None\n              • training=True\n        \n        \n        Call arguments received by layer 'distilbert' (type TFDistilBertMainLayer):\n          • input_ids=tf.Tensor(shape=(16, 16, 128), dtype=int32)\n          • attention_mask=tf.Tensor(shape=(16, 16, 128), dtype=int32)\n          • head_mask=None\n          • inputs_embeds=None\n          • output_attentions=False\n          • output_hidden_states=False\n          • return_dict=True\n          • training=True\n    \n    \n    Call arguments received by layer 'tf_distil_bert_for_sequence_classification' (type TFDistilBertForSequenceClassification):\n      • input_ids={'input_ids': 'tf.Tensor(shape=(16, 16, 128), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(16, 16, 128), dtype=int32)'}\n      • attention_mask=None\n      • head_mask=None\n      • inputs_embeds=None\n      • output_attentions=None\n      • output_hidden_states=None\n      • return_dict=None\n      • labels=tf.Tensor(shape=(16, 16), dtype=int32)\n      • training=True\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "print(\"Starting training...\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
